1、什么是ChatGPT
2、AI革命正在到来
3、和我们有什么关系
4、当前的局限性
5、未来的发展趋势
6、我们可以做什么
6.1 数据安全
6.2 个人开发者->公司 更加容易


## ChatGPT的使用
I. ChatGPT简介
A. 什么是ChatGPT
ChatGPT是一种基于OpenAI的GPT（Generative Pre-trained Transformer）模型的变体，专门设计用于生成对话。
GPT模型是一种基于深度学习的自然语言处理模型，它可以生成连贯的自然语言文本。

B. ChatGPT的工作原理
ChatGPT是一种基于深度学习的语言模型，使用了transformer架构。它由大量文本数据训练而成，可以产生人类类似的自然语言回复。
它的工作原理是通过接收用户输入的文本，使用预训练好的神经网络模型生成回复。
在生成回复时，ChatGPT尝试预测下一个最可能出现的词汇，并在此基础上生成连贯的、意义明确的回复。
闲聊模式下，ChatGPT会根据输入自动补全并生成对话。
ChatGPT作为大语言模型，其核心逻辑事实上是海量数据的收集、加工、处理和运算结果的输出。


早期的AI要靠人工打标签，要一个活人坐在屏幕前告诉机器——这是一只猫，这是一只狗；之后发展到GPT3，这时已经不用再打标，而是让机器直接去阅读大量的数据，看它能不能找出里面蕴含的规律和规则。


C. ChatGPT的能力和用途
ChatGPT具有广泛的能力和用途，以下是一些常见的应用场景：
聊天机器人&信息查询和推荐：https://chat.openai.com/
客户支持和服务：https://heyday.hootsuite.com/
语言学习：https://callsam.ai/
虚拟角色和游戏对话：https://www.aidungeon.io/ 、 https://www.woebot.io/
虚拟AI男/女友：https://www.herchatgpt.com/
微信/QQ聊天机器人：https://github.com/zhayujie/chatgpt-on-wechat
量化投资：https://www.aidyfin.com/
AI绘画：https://www.thiswaifudoesnotexist.net/
创作助手：(小红书小作文生成器)https://open-gpt.app/app/clf2awmv0001mjt08hjtcpe90
教育和培训：https://dreamstudio.ai/generate


* [ ] 和我们有什么关系
编程相关：
1）集成IDE的AI代码助手：tabnine.com
2）智能测试(融资1100万美元)：https://www.codium.ai/（Python、JavaScript 和 TypeScript）
3）渗透测试：https://github.com/GreyDGL/PentestGPT
4）commit message：https://github.com/zurawiki/gptcommit
5）基于聊天的SQL客户端：https://github.com/sqlchat/sqlchat/tree/main
6）gpt驱动的代码编辑器：https://www.cursor.so/、https://github.com/features/preview/copilot-x

* ChatGPT 开发
  https://platform.openai.com/docs/api-reference/introduction
* 在国内用网页科学上网访问可能导致API Key被封，无法使用API开发

VII. ChatGPT的局限性和未来发展
A. 模型的局限性和偏见
生成式模型的限制：ChatGPT 是一个生成式模型，它通过预测下一个可能的词来生成响应。这可能导致一些不准确或不合适的回答，特别是当模型遇到不常见的问题或需要领域专业知识时。
信息的遗忘：由于模型的有限记忆，ChatGPT 在长对话中可能会忘记一些先前的信息。这可能导致模型的回复与整个对话历史不一致或缺乏连贯性。
对训练数据的依赖：ChatGPT 模型的表现取决于其所训练的数据。如果训练数据中存在偏见、错误或不准确的信息，模型可能会重复或放大这些问题，并对敏感话题或具有潜在偏见的内容做出不恰当的回应。
语言生成的安全性问题：由于生成式模型的特性，ChatGPT 模型可能受到滥用，用于生成有害、欺诈、误导性或不当内容。确保模型的安全使用是非常重要的。

B. 处理模型输出的风险和挑战
错误和不准确性：生成式模型可能会生成错误、不准确或模棱两可的回答。这可能是由于训练数据中的错误或模糊性，或者模型的局限性所导致的。为了应对这个问题，可以考虑使用验证和审查机制来检查模型输出的准确性，并引入人工审核或后处理步骤来纠正潜在的错误。
偏见和不当内容：生成式模型可能会受到训练数据中的偏见影响，并且在生成回答时可能会表现出不当或有害的行为。为了解决这个问题，可以进行数据清洗和预处理，确保训练数据的多样性和公正性。此外，通过追踪和纠正模型输出中的偏见，并进行审查和监督，可以降低偏见和不当内容的风险。
安全性和合规性：生成式模型的滥用可能导致生成有害、欺诈或违法的内容。为了确保模型的安全性和合规性，可以考虑使用过滤器、审核机制和访问控制，以防止不当或有害的内容被发布。同时，建立明确的使用政策和道德准则，对模型的使用进行约束和指导。
隐私和敏感信息：生成式模型可能会在回答中泄露敏感信息或隐私数据。为了保护用户的隐私和敏感信息，可以考虑对模型进行脱敏或限制访问权限，确保模型在处理敏感数据时遵守隐私法规和最佳实践。
可解释性和透明性：生成式模型通常被认为是黑盒模型，难以解释其决策和推理过程。为了增强模型的可解释性和透明性，可以采用技术手段如注意力可视化、解释性生成等，以提供更清晰的模型解释和理解。

C. OpenAI的未来发展方向
1）OpenAI等企业会继续向着通用人工智能的方向努力，延承‘暴力美学’，做更大的模型、更多的参数、更多的模态，探索大模型的天花板，
以前的AI做的大多是弱人工智能（特定领域，解决特定问题）
大模型是强人工智能（通用领域，胜任人类所有工作）

在通用模型应用上，一定是解决了"信息的遗忘"问题的大模型取胜，
例如AI女友，大家肯定会希望记住自己喜好的女友，而不是今天谈的好好的，明天名字都忘记的女友

2）定制化、私有化
为什么要做定制化？
2。1）大模型定制化的挑战，在于对算力和数据的高门槛需求—— 
试想GPT3 一次训练的成本就上千万美元 —— 使得目前每家企业，甚至每个行业做一个专有大模型是不太现实的

3）需加快推动“隐私计算”技术在AIGC领域的应用。
让多个数据拥有者在不暴露数据本身的前提下，通过共享SDK或者开放SDK权限的方式，
在进行数据的共享、互通、计算、建模，在确保AIGC能够正常提供服务的同时，保证数据不泄露给其他参与方。

3） 数据安全是使用AI的保险箱
数据泄漏新闻：https://securityintelligence.com/articles/chatgpt-confirms-data-breach/
意大利等多个国家限制，禁用ChatGPT： https://www.sohu.com/a/665628714_120141411
意大利封禁ChatGPT所援引的法律工具是欧盟《通用数据保护条例》（GDPR）

3。1）针对toB的大模型，沙箱要求会很严格，必不可少的每条对话审计、实名制、敏感信息过滤、监控预警
3。2）针对toC，更多会使用通用的大模型，技术难度会更大，实名制也八成没法落实，用户数据质量会可预见的低
距离用户更近的风险是，用户在使用ChatGPT等AI工具时，可能会不经意间将私密数据输入到云端模型，这些数据可能成为训练数据，也可能成为提供给他人答案的一部分，从而导致数据泄露和合规风险。

技术上：蒸馏、裁剪等各种方法，都是在尝试用更小的模型去复现大模型的能力


* 官网通篇都在讲安全，https://openai.com/

1、生成图像
* https://openai.com/dall-e-2
* 安全缓解措施：
1）通过从训练数据中删除最露骨的内容，我们最小化了 DALL·E 2对这些概念的接触。我们还使用先进的技术来防止真实人物的面部（包括公众人物的面部）的逼真。
2）如果我们的过滤器发现可能违反我们政策的文本提示和图片上传，我们不会生成图片。我们还有自动化和人工监控系统，以防止滥用。
3）从现实世界的使用中学习是负责任地开发和部署人工智能的重要组成部分。我们从预览DALL·E 2 到有限数量的受信任用户。

* propmts: https://github.com/f/awesome-chatgpt-prompts、https://chat.plexpt.com/

* 开发者
* 开发者工具2.0时代，AI化，智能化，自然语言化

* ppt: https://pdf.dfcfw.com/pdf/H3_AP202302081582885375_1.pdf?1675867050000.pdf

* chatgpt在数据安全上的问题
* 以AI客服为例
ChatGPT需要针对企业的个性化知识库进行训练，才能回答企业的个性化问题。这就需要ChatGPT在云端开放其训练能力，并且要求企业将自己的知识库上传到云端做训练。
但ChatGPT训练一次的费用对企业来讲是一个天价，因此ChatGPT的商业化需要将模型裁剪到合适的规模，在合理的费用和时间内完成训练，才能适应一般企业的需求。
但裁剪的同时，又需要保留原有的问答体验。
* 其次就是数据安全、数据隔离的问题。
  大部分企业都不希望把自己的专有知识库上传到公开的领域里，训练一个公开的模型，这个模型还被其他人共享，这样就会造成数据的泄露。
  一些银行数据、保险数据，不可能放在互联网上给外界访问，需要有一个物理隔离，所有的访问权限相当于在局域网之内，ChatGPT也是在局域网施展能力。
  但这个能力肯定会受限制，说白了，答案的丰富度是基于数据来的，数据受限的情况下，ChatGPT只能说是比较好用的机器人，效果和能在全网搜索解决方案相比，肯定是不一样的

* 难点在于：AI没有判断力，还支撑不住很多欺骗方式。防护策略在行业里推动很难，防护难度很大。
* 痛点在于：在不侵犯客户隐私的情况下，怎么能通过之前给客户提供的服务，还有客户之前的反馈诉求，对客户的需求有更深刻的洞察

* 目前最直接的方式就是像当前的银行客服一样，涉及到到密码之类的信息，让客户手动按键输入，而不是口诉，
* 换算到ai上，可以在模型接受到密码之类的信息前，先经过沙箱处理，然后再进入模型，这样就可以保证客户的隐私安全了


* 公司已经开始做小型化的ChatGPT，类ChatGPT的模型


* 结论：未来肯定会导致多种工种的岗位变少，但是也有诞生新工种的机会。
https://www.trendmicro.com/zh_hk/devops/23/e/chatgpt-security-vulnerabilities.html



新职业
1、chatGPT训练师（AI公司）
2、chatGPT社群俱乐部



